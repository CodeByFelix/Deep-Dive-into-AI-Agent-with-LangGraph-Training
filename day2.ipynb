{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb52cb00",
   "metadata": {},
   "source": [
    "## Agent Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc295325",
   "metadata": {},
   "source": [
    "### Initializing LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7974030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9296616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\", api_key=os.getenv (\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cec0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"What is Agentic AI\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7225b9a",
   "metadata": {},
   "source": [
    "### Building a simple Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END, MessagesState\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "sys_prompt = \"\"\"You are an expert assistante for using VSCode.\n",
    "You are to give the user guidance on using VScode.\n",
    "you are to responde to message on VScode only.\n",
    "If the user asked a question not related to VSCode, response that you are only an assistante for VScode and can only response to messages concerning VSCode.\"\"\"\n",
    "\n",
    "sys_msg = SystemMessage (content=sys_prompt)\n",
    "def llm_call (state:MessagesState) -> MessagesState:\n",
    "    msg = state['messages']\n",
    "    response = llm.invoke ([sys_msg] + msg)\n",
    "    return {'messages': response}\n",
    "\n",
    "builder = StateGraph (MessagesState)\n",
    "builder.add_node ('LLM Call', llm_call)\n",
    "\n",
    "builder.add_edge (START, 'LLM Call')\n",
    "builder.add_edge ('LLM Call', END)\n",
    "\n",
    "graph = builder.compile ()\n",
    "\n",
    "from IPython.display import display, Image\n",
    "\n",
    "display (Image (graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75440c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbdd7e54",
   "metadata": {},
   "source": [
    "### Building Tools for an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b8cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply (a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiply a and b\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a*b\n",
    "\n",
    "@tool\n",
    "def add (a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Adds a and b\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a+b\n",
    "\n",
    "\n",
    "tools = [multiply, add]\n",
    "llm_with_tool = llm.bind_tools (tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ba792c",
   "metadata": {},
   "source": [
    "### Defining Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66681529",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_prompt = \"\"\"You are an expert assistant for performing arithmetic operations.\n",
    "You have tools for addition, subtraction, multiplication, and division.\n",
    "You are to respond only to arithmetic-related questions.\n",
    "If the user asks anything unrelated to arithmetic, reply that you can only assist with arithmetic operations.\"\"\"\n",
    "\n",
    "\n",
    "sys_msg = SystemMessage(content= sys_prompt)\n",
    "\n",
    "def assistant (state: MessagesState) -> MessagesState:\n",
    "    response = llm_with_tool.invoke ([sys_msg] + state ['messages'])\n",
    "    return {'messages': response}\n",
    "\n",
    "\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "builder = StateGraph (MessagesState)\n",
    "builder.add_node ('tools', ToolNode(tools))\n",
    "builder.add_node ('assistant', assistant)\n",
    "\n",
    "builder.add_edge (START, 'assistant')\n",
    "builder.add_conditional_edges ('assistant', tools_condition)\n",
    "builder.add_edge ('tools', END)\n",
    "\n",
    "graph = builder.compile ()\n",
    "\n",
    "#print (graph.get_graph().draw_mermaid())\n",
    "display (Image (graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d38de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What can you do for me\"\n",
    "response = graph.invoke (input={'messages': [HumanMessage(content=query)]})\n",
    "\n",
    "for m in response['messages']:\n",
    "    m.pretty_print ()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b66f4",
   "metadata": {},
   "source": [
    "### Making it smart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3c5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph (MessagesState)\n",
    "builder.add_node ('tools', ToolNode(tools))\n",
    "builder.add_node ('assistant', assistant)\n",
    "\n",
    "builder.add_edge (START, 'assistant')\n",
    "builder.add_conditional_edges ('assistant', tools_condition)\n",
    "builder.add_edge ('tools', 'assistant')\n",
    "\n",
    "graph = builder.compile ()\n",
    "\n",
    "display (Image( (graph.get_graph().draw_mermaid_png())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64b03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18f58bfe",
   "metadata": {},
   "source": [
    "### Web search\n",
    "\n",
    "pip install tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d26d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "TavilySearch = TavilyClient (api_key=os.getenv (\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchResult = TavilySearch.search (query=\"latest Anambra state governorship election results\",\n",
    "                                    max_results=3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2bc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchResult['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ff40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchContent = \"\"\n",
    "\n",
    "for result in searchResult['results']:\n",
    "    content = f\"\"\"Source: {result['url']}\n",
    "Content: {result['content']}\\n\\n\"\"\"\n",
    "    searchContent += content\n",
    "\n",
    "print (searchContent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf3b86a",
   "metadata": {},
   "source": [
    "### ChatBot with realtime websearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fde09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def searchTool (query:str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the web in real-time and returns the response.\n",
    "\n",
    "    Args:\n",
    "        query: String--A query to search in the web\n",
    "    \"\"\"\n",
    "    searchResult = TavilySearch.search (query=query,\n",
    "                                    max_results=5,)\n",
    "    searchContent = \"\"\n",
    "\n",
    "    for result in searchResult['results']:\n",
    "        content = f\"\"\"Source: {result['url']}\n",
    "    Content: {result['content']}\\n\\n\"\"\"\n",
    "        searchContent += content\n",
    "\n",
    "    return searchContent\n",
    "\n",
    "tools = [searchTool]\n",
    "llm_search = llm.bind_tools (tools=tools)\n",
    "\n",
    "sys_prompt = \"\"\"You are an intelligent assistant that can answer any question.\n",
    "If you know the answer, respond directly.\n",
    "If you do not know the answer, use your web search tool to find the information in real-time and respond accurately.\n",
    "Always provide clear and helpful answers based on the information available.\"\"\"\n",
    "\n",
    "sys_msg = SystemMessage (content=sys_prompt)\n",
    "\n",
    "def assistant (state:MessagesState) -> MessagesState:\n",
    "    msg = state['messages']\n",
    "    response = llm_search.invoke ([sys_msg] + msg)\n",
    "    return {'messages': response}\n",
    "\n",
    "\n",
    "builder = StateGraph (MessagesState)\n",
    "builder.add_node ('tools', ToolNode(tools))\n",
    "builder.add_node ('assistant', assistant)\n",
    "\n",
    "builder.add_edge (START, 'assistant')\n",
    "builder.add_conditional_edges ('assistant', tools_condition)\n",
    "builder.add_edge ('tools', 'assistant')\n",
    "\n",
    "graph = builder.compile ()\n",
    "\n",
    "display (Image( (graph.get_graph().draw_mermaid_png())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who are youS\"\n",
    "msg = HumanMessage (content= query)\n",
    "\n",
    "response = graph.invoke (input={'messages': [msg]})\n",
    "\n",
    "for m in response['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062652ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
